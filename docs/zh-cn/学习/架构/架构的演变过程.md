前提先知：什么是数据中心 什么云服务？？

数据中心 的地域（Region）和可用区（Availability Zone，AZ）理解

简单来说，可以将**地域**理解为不同城市的机房，将**可用区**理解为同一个城市的不同机房。当然，实际上不同可用区也可能是在同一个机房，**可用区**的概念严格来说是按**照电力和网络设备**等相互独立来设计的。同一个地域内的不同可用区之间，内网是连通的，但是网络的响应时间会有差异。



#	1.大型网站的特点

+ 高并发，大流量
  需要面对高并发用户，大流量访问。Google日均PV()数61亿，日均IP访问数4亿；淘宝日均PV 1亿，日均IP4千万
+ 高可用
  系统 7 x 24 小时不间断服务。
+ 海量数据
  需要存储、管理海量数据，需要使用大量服务器。
+ 用户分部广泛，网络情况复杂
  许多大型互联网站都是为全球用户提供服务的，用户分布范围广，各地网络情况千差万别。在国内，还有各个运营商网络互通难的问题。
+ 安全环境恶劣
  由于互联网的开放性，使得互联网站更容易受到攻击，大型网站几乎每天都会被黑客攻击。
+ 需求快速变更，发布频繁
  和传统软件的版本发布频率不同，互联网产品为快速适应市场，满足用户需求，其产品发布频率极高。一般大型网站的产品每周都有新版本发布上线，中小型网站的发布更频繁，有时候一天会发布几十次。
+ 渐进式发展
  几乎所有的大型互联网网站都是从一个小网站开始，渐进地发展起来的。好的互联网产品都是慢慢运营出来的，不是一开始就开发好的，这也正好与网站架构的发展演化过程对应。





#	2.相关术语

##	2.1 分层

大型网站架构中常采用分层结构，将软件系统分为应用层、服务层、数据层：

- 应用层 - 负责具体业务和视图展示。如网站首页及搜索输入和结果展示。
- 服务层 - 为应用层提供服务支持。如用户管理服务、购物车服务等。
- 数据层 - 提供数据存储访问服务。如数据库、缓存、文件、搜索引擎等。

分层架构的约束：禁止跨层次的调用（应用层直接调用数据层）及逆向调用（数据层调用服务层，或者服务层调用应用层）。
tips：分层结构内部还可以继续分层



##	2.2 服务分割

将不同的功能和服务分割开来，包装成高内聚低耦合的模块单元。这有助于软件的开发和维护，便于不同模块的分布式部署，提高网站的并发处理能力和功能扩展能力。



##	2.3 分布式
+ **什么是CAP理论？**
  在分布式系统环境下，由于存在硬件、网络的隔离，对于一些事务操作不像单机环境下那样简单，于是出现了CAP理论。它的定义如下：
  **Consistency（一致性） **由于分布式环境存在多个节点，这些节点上的数据在同一时间所存储的数据必须是一致的，这就是一致性协议。在并发环境下一个客户端从任何一个节点获取的数据如何保证是最新的。对于服务端来说，需要保证在整个分布式环境下的数据复制问题。
  **Availability（可用性）** 可用性很好理解，任何时刻需要保证服务的可用和稳定。
  **Partition Tolerance（分区容错）** 所谓分区容错是指某个时刻出现网络或者硬件不可用，甚至宕机，其它的机器还能保证正常可用。

  大部分情况下我们能够很好的保证可用性和分区容错，但是对于一致性问题一直很难保证。
  对于大型网站，分层和分割的一个主要目的是为了切分后的模块便于分布式部署，即将不同模块部署在不同的服务器上，通过远程调用协同工作。
  分布式意味可以用更多的机器工作，那么 CPU、内存、存储资源也就更丰富，能够处理的并发访问和数据量就越大，进而能够为更多的用户提供服务。



- **分布式也引入了一些问题：**

  + 服务调用必须通过网络，网络延迟会影响性能
  + 服务器越多，宕机概率也越大，可用性降低
  + 数据一致性非常困难，分布式事务也难以保证
  + 服务依赖错综复杂，开发管理维护困难

  

- **常用的分布式方案：**

  + 分布式应用和服务
  + 分布式静态资源
  + 分布式数据和存储
  + 分布式计算



##	2.4 集群

集群即多台服务器部署相同应用构成一个集群，通过负载均衡设备共同对外提供服务。

集群需要具备伸缩性和故障转移机制：伸缩性是指可以根据用户访问量向集群添加或减少机器；故障转移是指，当某台机器出现故障时，负载均衡设备或失效转移机制将请求转发到集群中的其他机器上，从而不影响用户使用。



##	2.5 缓存

缓存就是将数据存放在距离最近的位置以加快处理速度。缓存是改善软件性能的第一手段。网站应用中，缓存除了可以加快数据访问速度以外，还可以减轻后端应用和数据存储的负载压力。

**常见缓存手段：**

* CDN高速缓存
* 反向代理
* 本地缓存
* 分布式缓存



**哪些数据需要放入缓存？**

+ 频繁访问的数据应该放在缓存中
+ 不经常改动的数据



##	2.6 冗余--》服务高可用

大型网站，出现服务器宕机是必然事件。要保证部分服务器宕机的情况下网站依然可以继续服务，不丢失数据，就需要一定程度的服务器冗余运行，数据冗余备份。这样当某台服务器宕机时，可以将其上的服务和数据访问转移到其他机器上。

访问和负载很小的服务也必须部署 至少两台服务器构成一个集群，目的就是通过冗余实现服务高可用。数据除了定期备份，存档保存，实现 **冷备份** 外；为了保证在线业务高可用，还需要对数据库进行主从分离，实时同步实现 **热备份**。

为了抵御地震、海啸等不可抗因素导致的网站完全瘫痪，某些大型网站会对整个数据中心进行备份，全球范围内部署 灾备数据中心。网站程序和数据实时同步到多个灾备数据中心。







#	3.大型架构的演变过程

##	3.1 单机网站：初始阶段的网站架构

小型网站最开始没有太多人访问，只需要一台服务器就绰绰有余，应用程序、数据库、文件等所有资源都在一台服务器上

![](https://raw.githubusercontent.com/guohangbk/picBed/master/img/1579102764.png)



##	3.2 单机负载告警，应用服务与数据服务（DB）分离

随着网站业务的发展，一台服务器逐渐不能满足需求。越来越多的用户访问导致性能越来越差，越来越多的数据导致存储空间不足。这时就需要将应用和数据分离。应用和数据分离后整个网站使用3台服务器：应用服务器、文件服务器和数据库服务器。这3台服务器对硬件资源的要求各不相同。

* 应用服务器需要处理大量的业务逻辑，因此需要更快更强大的CPU
* 数据库服务器需要快速磁盘检索和数据缓存，因此需要更快的磁盘和更大的内存
* 文件服务器需要存储大量用户上传的文件，因此需要更大的硬盘和带宽



##	3.3 应用服务器负载告警，使用应用服务器集群改善网站的并发处理能力(Nginx)

但是单一应用服务器能够处理的请求连接有限，在网站访问高峰期，应用服务器成为整个网站系统的瓶颈。使用集群是网站解决高并发、大流量问题的常用手段。
当一台服务器的处理能力、存储空间不足时，不要企图去更换更强大的服务器，对大型网站而言，不管多么强大的服务器，都满足不了网站持续增长的业务需求。这种情况下，更恰当的做法是增加一台服务器来分担原有服务器的访问及存储压力。
对网站架构而言，只要能通过增加一台服务器的方式来改善负载压力，就可以以同样的方式持续增加服务器不断改善系统性能，从而实现系统的可伸缩性。
应用服务器实现集群是网站可伸缩架构设计中较为简单成熟的一种。

* 什么是负载
  客户端向服务器发送的请求称之为服务器的负载
* 什么是负载均衡
  把客户端发送的请求按照某种规则分配到多台服务器上称之为负载均衡



##	3.4 数据库压力太大导致访问延迟，用缓存改善网站性能(Redis)

但是随着用户逐渐增多，网站又一次面临挑战：数据库压力太大导致访问延迟，进而影响整个网站的性能，用户体验受到影响。这时需要对网站架构进一步优化。

网站访问的特点和现实世界的财富分配一样遵循**二八定律**：80%的业务访问集中在20%的数据上(热点数据）。 既然大部分业务访问集中在一小部分数据上，那么如果把这一小部分数据缓存在内存中，就可以减少数据库的访问压力，提高整个网站的数据访问速度，改善数据库的写入性能了。

网站使用的缓存可以分为两种：缓存在应用服务器上的**本地缓存**和缓存在专门的分布式缓存服务器上的**远程缓存**。



> * 本地缓存的访问速度更快一些，但是受应用服务器内存限制，其缓存数据量有限，而且会出现和应用程序争用内存的情况
> * 远程分布式缓存可以使用集群的方式，部署大内存的服务器作为专门的缓存服务器，可以在理论上做到不受内存容量限制的缓存服务

![](https://raw.githubusercontent.com/guohangbk/picBed/master/img/1579102297.png)



##	3.5 数据库压力依然大，数据库读写分离（Mycat）分库分表

网站在使用缓存后，使对大部分数据读操作访问都可以不走数据库就能完成，但是仍有一部分读操作（缓存访问不命中、缓存过期）和全部的写操作都需要访问数据库。 在网站的用户达到一定规模后，数据库因为负载压力过高而成为网站的瓶颈。 目前大部分的主流数据库都提供主从热备功能，通过配置两台数据库主从关系，可以将一台数据库服务器的数据更新同步到另一台服务器上。网站利用数据库的这一功能，实现数据库**读写分离**，从而改善数据库负载压力，即**主写从读，然后主从同步复制**。

应用服务器在写数据的时候，访问主数据库，主数据库通过主从复制机制将数据更新同步到从数据库，这样当应用服务器读数据的时候，就可以通过从数据库获得数据。

![img](E:\电脑软件\有道云笔记\数据\guohangbk@163.com\cea1fd3a7fb846e2b984f3fb5bd366aa\clipboard.png)

继续优化就是分库分表，分库分表就是把非常大的数据库切分成很多小的表，并且把这些表存放在不同的数据库中，这些小表整合在一起才是完整的数据库。

![](https://raw.githubusercontent.com/guohangbk/picBed/master/img/1579102418.png)



##	3.6 弥补关系型数据库的不足，使用NoSql和搜索引擎（ES）

随着网站业务越来越复杂，对数据存储和检索的需求也越来越复杂，网站需要采用一些**非关系数据库**技术如NoSQL和非数据库查询技术如搜索引擎。

**NoSql和搜索引擎**都是源自互联网的技术手段，对可伸缩的分布式特性具有更好的支持。应用服务器则通过一个统一数据访问模块访问各种数据，减轻应用程序管理诸多数据源的麻烦。

![](https://raw.githubusercontent.com/guohangbk/picBed/master/img/1579102459.png)



##	3.7 使用反向代理和CDN加速网站响应

CDN的全称是(Content Delivery Network)，即内容分发网络。其目的是通过在现有的Internet中增加一层新的CACHE(缓存)层，将网站的内容发布到最接近用户的网络”边缘“的节点，使用户可以就近取得所需的内容，提高用户访问网站的响应速度。

随着网站业务不断发展，用户规模越来越大，由于国内复杂的网络环境，不同地区的用户访问网站时，访问速度有时候差别很大。有研究表明，网站访问延迟和用户流失率正相关，网站访问越慢，用户越容易失去耐心而离开。为了提供更好的用户体验，留住用户，网站需要加速网站访问速度。主要手段有使用CDN和反向代理。

CDN 和反向代理的基本原理都是缓存

> * CDN 部署在网络提供商的机房，使用户在请求网站服务时，可以从距离自己最近的网络提供商机房获取数据
> * 反向代理则部署在网站的中心机房，当用户请求到达中心机房后，首先访问的服务器是反向代理服务器，如果反向代理服务器中缓存着用户请求的资源，就将其直接返回给用户

使用 CDN 和反向代理的目的都是尽早返回数据给用户，一方面加快用户访问速度，另一方面也减轻后端服务器的负载压力。

CDN服务商将源站的资源缓存到遍布全国的高性能加速节点上，当用户访问相应的业务资源时，用户会被调度至最接近的节点最近的节点ip返回给用户，在web性能优化中，它主要起到了，缓解源站压力，优化不同用户的访问速度与体验的作用。

解决服务器端的“第一公里”问题

![](https://raw.githubusercontent.com/guohangbk/picBed/master/img/1579102520.png)

##	3.8 业务拆分

大型网站为了应对日益复杂的业务场景，通过使用分而治之的手段**将整个网站业务分成不同的产品线**。如大型购物交易网站都会将首页、商铺、订单、买家、卖家等拆分成不同的产品线，分归不同的业务团队负责。 

具体到技术上，也会根据产品线划分，**将一个网站拆分成许多不同的应用，每个应用独立部署**。应用之间可以通过一个超链接建立关系（在首页上的导航链接每个都指向不同的应用地址），也可以通过消息队列进行数据分发，当然最多的还是通过访问同一个数据存储系统来构成一个关联的完整系统。

每一个业务独占一个工程，打出来的就是一个jar包，发布的时候可以使用一台独立的服务器。

![](https://raw.githubusercontent.com/guohangbk/picBed/master/img/1579102635.png)



##	3.9 使用分布式微服务框架解决服务无法治理的问题

拆分之后的业务越来越多，多的没有办法管理。需要有一个框架来实现服务的治理。dubbo以及springcloud来实现服务的治理。

![](https://raw.githubusercontent.com/guohangbk/picBed/master/img/1579102674.png)



